{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 "
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qcCCYWqFdH72",
        "outputId": "2701d3c7-de38-4976-9a67-3703c433fce0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm facenet-pytorch opencv-python-headless\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck4nydFedX_L",
        "outputId": "9e855496-0edb-4d7c-fc93-5fe6eed2cf68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.2.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.17.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.31.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (1.26.4)\n",
            "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (10.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (2.32.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.5.82)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->timm) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INSTALL LIBRARIES"
      ],
      "metadata": {
        "id": "EPaVmrzMgdSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from facenet_pytorch import MTCNN\n",
        "import timm\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "VT4r_HiqfNL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INITIALISE FACE DETECTOR (MTCNN)"
      ],
      "metadata": {
        "id": "esCR8_FoglWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "mtcnn = MTCNN(image_size=224, margin=20, device=device)"
      ],
      "metadata": {
        "id": "U1weNgUYfadm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINE FACE FRAME EXTRACTOR"
      ],
      "metadata": {
        "id": "zAG7VkMjgqcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_faces(video_path, max_frames=16):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    faces = []\n",
        "    while len(faces) < max_frames and cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        face = mtcnn(frame)\n",
        "        if face is not None:\n",
        "            faces.append(face)\n",
        "    cap.release()\n",
        "    if len(faces) == 0:\n",
        "        return None\n",
        "    return torch.stack(faces)\n"
      ],
      "metadata": {
        "id": "D4wiEUSefcmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientViT Encoder"
      ],
      "metadata": {
        "id": "6zTvGkIGgwy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EfficientViTEmbedder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model('efficientvit_b1.r224_in1k', pretrained=True, features_only=True)\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)[-1]\n",
        "        x = self.pool(x).squeeze(-1).squeeze(-1)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "HG2ihNVqfhL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEMPORAL ConvNet Classifier"
      ],
      "metadata": {
        "id": "LIO6erMcg3wL"
      }
    },
    {
      "source": [
        "class DeepfakeClassifier(nn.Module):\n",
        "    def __init__(self, embed_dim=256):\n",
        "        super().__init__()\n",
        "        self.temporal = nn.Sequential(\n",
        "            nn.Conv1d(embed_dim, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Linear(256, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.temporal(x).squeeze(-1)\n",
        "        return torch.sigmoid(self.fc(x)).squeeze(1)\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "KZqwhD_1h9fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATASET LOADER"
      ],
      "metadata": {
        "id": "5mRJ896jhE3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepfakeDataset(Dataset):\n",
        "    def __init__(self, folder, max_frames=16):\n",
        "        self.samples = []\n",
        "        for label, sub in enumerate(['real', 'fake']):\n",
        "            files = glob.glob(os.path.join(folder, sub, '*.mp4'))\n",
        "            self.samples += [(f, label) for f in files]\n",
        "        self.max_frames = max_frames\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.samples[idx]\n",
        "        faces = extract_faces(path, self.max_frames)\n",
        "        if faces is None:\n",
        "            return self.__getitem__((idx + 1) % len(self.samples))\n",
        "        return faces, torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n"
      ],
      "metadata": {
        "id": "H5L7NdUagLLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING"
      ],
      "metadata": {
        "id": "47QGgApMhKmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedder = EfficientViTEmbedder().to(device).eval()\n",
        "classifier = DeepfakeClassifier().to(device)\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/deepfake_dataset/deepfake_dataset/test\"\n",
        "train_data = DeepfakeDataset(train_path)\n",
        "train_loader = DataLoader(train_data, batch_size=2, shuffle=True)\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)\n"
      ],
      "metadata": {
        "id": "363M4FhMgNkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING LOOP"
      ],
      "metadata": {
        "id": "svJukB5rhNfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(8):\n",
        "    for frames, labels in tqdm(train_loader):\n",
        "        B, T, C, H, W = frames.shape\n",
        "        frames = frames.view(B*T, C, H, W).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            feats = embedder(frames)\n",
        "\n",
        "        feats = feats.view(B, T, -1)\n",
        "        preds = classifier(feats)\n",
        "        loss = loss_fn(preds, labels.to(device))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S4bYaR0gPOm",
        "outputId": "d6742ad8-8408-4762-cc3f-15935052d63c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:04<00:00,  3.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.2240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:03<00:00,  3.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 0.4184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:02<00:00,  3.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 0.2183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:02<00:00,  3.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 0.0968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:02<00:00,  3.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 0.0338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:02<00:00,  3.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 0.0386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:02<00:00,  3.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 0.0330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:03<00:00,  3.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 0.1504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST ON DATASET + EVALUATION"
      ],
      "metadata": {
        "id": "xihIix6UhPXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = \"/content/drive/MyDrive/deepfake_dataset/deepfake_dataset/test\"\n",
        "test_data = DeepfakeDataset(test_path)\n",
        "test_loader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "def evaluate_model(embedder, classifier, dataloader):\n",
        "    classifier.eval()\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for frames, labels in tqdm(dataloader):\n",
        "            B, T, C, H, W = frames.shape\n",
        "            frames = frames.view(B*T, C, H, W).to(device)\n",
        "\n",
        "            feats = embedder(frames)\n",
        "            feats = feats.view(B, T, -1)\n",
        "\n",
        "            preds = classifier(feats)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "    y_pred_bin = [1 if p > 0.45 else 0 for p in y_pred]\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred_bin)\n",
        "    auc = roc_auc_score(y_true, y_pred)\n",
        "    cm = confusion_matrix(y_true, y_pred_bin)\n",
        "\n",
        "    print(f\"\\n Accuracy: {acc:.4f}\")\n",
        "    print(f\" AUC Score: {auc:.4f}\")\n",
        "    print(f\" Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "evaluate_model(embedder, classifier, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7gOEneKgSlm",
        "outputId": "e1af2fad-2d36-4288-964a-16edac05e194"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [01:03<00:00,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Accuracy: 1.0000\n",
            " AUC Score: 1.0000\n",
            " Confusion Matrix:\n",
            "[[20  0]\n",
            " [ 0 20]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}
